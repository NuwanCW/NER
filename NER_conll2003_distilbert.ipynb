{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_conll2003_distilbert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmU1vNYBaKfZI6pKzg9hXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5568e1c734ea4e13b4ff7bd5583ce4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3575a467e48d48bdbf6f1ffd1cbe120f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0737e1b2ed2e427eb768435de15db766",
              "IPY_MODEL_21d09c894b114c6b92c5c90bb952ba15",
              "IPY_MODEL_05349fec270b4646b3ff4fc0ad5e1efa"
            ]
          }
        },
        "3575a467e48d48bdbf6f1ffd1cbe120f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0737e1b2ed2e427eb768435de15db766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af92f8216c564d5cbce061ad24294600",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a04ba3ce1394db79fb62a9deafed65e"
          }
        },
        "21d09c894b114c6b92c5c90bb952ba15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d086a1cd08a4621b3a21a2614e156c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1d3979800224b51b92333fc2894aecd"
          }
        },
        "05349fec270b4646b3ff4fc0ad5e1efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b02526e176544532a115eac987c601b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 11.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_656ca7b0eeb34ec18fba2bbe37802fd8"
          }
        },
        "af92f8216c564d5cbce061ad24294600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a04ba3ce1394db79fb62a9deafed65e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d086a1cd08a4621b3a21a2614e156c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1d3979800224b51b92333fc2894aecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b02526e176544532a115eac987c601b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "656ca7b0eeb34ec18fba2bbe37802fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66c461f186c341dd842fcf041d800758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a3ca8cf36874b4191a3c8a8bb72b8d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db70da18ce5140fba23e964d5b9d7cd2",
              "IPY_MODEL_23d49ff962084ca79505bfa48f2fe7b4",
              "IPY_MODEL_f16412a76e31424c84ce4150c47e8a38"
            ]
          }
        },
        "9a3ca8cf36874b4191a3c8a8bb72b8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "db70da18ce5140fba23e964d5b9d7cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cbaab0abe814caa9f5407b0637cf66e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72ea52e2cea54049b7c34e77feddad09"
          }
        },
        "23d49ff962084ca79505bfa48f2fe7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9760715e310c4fb9a4773e091c83096d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa5126718fe54aa0b67b5f9af49cefb6"
          }
        },
        "f16412a76e31424c84ce4150c47e8a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2231ae13c87c4bc5b577267464d968db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25e4cf339aed4874a63282286583258e"
          }
        },
        "3cbaab0abe814caa9f5407b0637cf66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72ea52e2cea54049b7c34e77feddad09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9760715e310c4fb9a4773e091c83096d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa5126718fe54aa0b67b5f9af49cefb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2231ae13c87c4bc5b577267464d968db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25e4cf339aed4874a63282286583258e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baa6bf6da8e84c54a3e4c9882574a414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdc1feab6eda476e8edbf160b8b72a18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f48db302a1b4c30aafccdcb9dd7d819",
              "IPY_MODEL_c58bfa529e714697910dbccb2f77671a",
              "IPY_MODEL_c47ef463635f4ebfb53af816a2366310"
            ]
          }
        },
        "cdc1feab6eda476e8edbf160b8b72a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4f48db302a1b4c30aafccdcb9dd7d819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66463dc7cbb2474da5faf8afe0da08fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Predicting: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84d5b4a6327a4a0188460f24267f3c1f"
          }
        },
        "c58bfa529e714697910dbccb2f77671a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1c265a2214c41ef9cd780e98e7631c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_835570069fa94ed0ae5087f077eaaa0d"
          }
        },
        "c47ef463635f4ebfb53af816a2366310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_669d40ed0a014c13ae13704e28455301",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 878/? [00:09&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7a2111cf276451c8adaf68374eb47a2"
          }
        },
        "66463dc7cbb2474da5faf8afe0da08fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84d5b4a6327a4a0188460f24267f3c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1c265a2214c41ef9cd780e98e7631c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "835570069fa94ed0ae5087f077eaaa0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "669d40ed0a014c13ae13704e28455301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7a2111cf276451c8adaf68374eb47a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NuwanCW/NER/blob/main/NER_conll2003_distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nSxTcJoyK8"
      },
      "source": [
        "import os, csv\n",
        "from itertools import compress\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
        "import transformers\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.preprocessing\n",
        "from argparse import ArgumentParser"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi92fiRMo1zV",
        "outputId": "b2ea48b6-b872-403b-ff3b-f152b32bf226"
      },
      "source": [
        "# !wget 'https://data.deepai.org/conll2003.zip' && unzip conll2003.zip && mkdir conll2003 && mv train.txt test.txt valid.txt conll2003/\n",
        "# !ls conll2003"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt  train.txt  valid.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "2fYkQhhApH8X",
        "outputId": "d57817db-00a5-4030-b7b4-8571486f4b0c"
      },
      "source": [
        "def get_conll_data(split: str = 'train', \n",
        "                   limit: int = None, \n",
        "                   dir: str = None) -> dict:\n",
        "    \"\"\"Load CoNLL-2003 (English) data split.\n",
        "    Loads a single data split from the \n",
        "    [CoNLL-2003](https://www.clips.uantwerpen.be/conll2003/ner/) \n",
        "    (English) data set.\n",
        "    Args:\n",
        "        split (str, optional): Choose which split to load. Choose \n",
        "            from 'train', 'valid' and 'test'. Defaults to 'train'.\n",
        "        limit (int, optional): Limit the number of observations to be \n",
        "            returned from a given split. Defaults to None, which implies \n",
        "            that the entire data split is returned.\n",
        "        dir (str, optional): Directory where data is cached. If set to \n",
        "            None, the function will try to look for files in '.conll' folder in home directory.\n",
        "    Returns:\n",
        "        dict: Dictionary with word-tokenized 'sentences' and named \n",
        "        entity 'tags' in IOB format.\n",
        "    Examples:\n",
        "        Get test split\n",
        "        >>> get_conll_data('test')\n",
        "        Get first 5 observations from training split\n",
        "        >>> get_conll_data('train', limit = 5)\n",
        "    \"\"\"\n",
        "    assert isinstance(split, str)\n",
        "    splits = ['train', 'valid', 'test']\n",
        "    assert split in splits, f'Choose between the following splits: {splits}'\n",
        "\n",
        "    # set to default directory if nothing else has been provided by user.\n",
        "    if dir is None:\n",
        "        dir = os.path.join(str(Path.home()), '.conll')\n",
        "    assert os.path.isdir(dir), f'Directory {dir} does not exist. Try downloading CoNLL-2003 data with download_conll_data()'\n",
        "    \n",
        "    file_path = os.path.join(dir, f'{split}.txt')\n",
        "    assert os.path.isfile(file_path), f'File {file_path} does not exist. Try downloading CoNLL-2003 data with download_conll_data()'\n",
        "\n",
        "    # read data from file.\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        reader = csv.reader(file, delimiter = ' ')\n",
        "        for row in reader:\n",
        "            data.append([row])\n",
        "\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    entities = []\n",
        "    tags = []\n",
        "\n",
        "    for row in data:\n",
        "        # extract first element of list.\n",
        "        row = row[0]\n",
        "        # TO DO: move to data reader.\n",
        "        if len(row) > 0 and row[0] != '-DOCSTART-':\n",
        "            sentence.append(row[0])\n",
        "            tags.append(row[-1])        \n",
        "        if len(row) == 0 and len(sentence) > 0:\n",
        "            # clean up sentence/tags.\n",
        "            # remove white spaces.\n",
        "            selector = [word != ' ' for word in sentence]\n",
        "            sentence = list(compress(sentence, selector))\n",
        "            tags = list(compress(tags, selector))\n",
        "            # append if sentence length is still greater than zero..\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                entities.append(tags)\n",
        "            sentence = []\n",
        "            tags = []\n",
        "            \n",
        "   \n",
        "    if limit is not None:\n",
        "        sentences = sentences[:limit]\n",
        "        entities = entities[:limit]\n",
        "    \n",
        "    return {'sentences': sentences, 'tags': entities}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-400c820ec231>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ydef get_conll_data(split: str = 'train',\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbVDuh4ipJkY"
      },
      "source": [
        "train_data = get_conll_data(split='train',dir='conll2003')\n",
        "val_data = get_conll_data(split='valid',dir='conll2003')\n",
        "test_data = get_conll_data(split='test',dir='conll2003')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS-yJRkfppuJ",
        "outputId": "743f7d0b-8e87-47f8-d8ec-80603b679ba2"
      },
      "source": [
        "print('train data size',len(train_data['sentences']))\n",
        "print('val data size',len(val_data['sentences']))\n",
        "print('test data size',len(test_data['sentences']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data size 14039\n",
            "val data size 3250\n",
            "test data size 3453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I9VjSXCqJOX",
        "outputId": "84f05da4-1dfd-4224-e10b-33a8714f244e"
      },
      "source": [
        "print(len(train_data['tags']))\n",
        "print(train_data['tags'][4])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14039\n",
            "['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD8_vJYZqOjf",
        "outputId": "31b8221e-f63b-46fb-d4e8-1b6d6473a40d"
      },
      "source": [
        "print(train_data['sentences'][4])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "5568e1c734ea4e13b4ff7bd5583ce4c7",
            "3575a467e48d48bdbf6f1ffd1cbe120f",
            "0737e1b2ed2e427eb768435de15db766",
            "21d09c894b114c6b92c5c90bb952ba15",
            "05349fec270b4646b3ff4fc0ad5e1efa",
            "af92f8216c564d5cbce061ad24294600",
            "5a04ba3ce1394db79fb62a9deafed65e",
            "9d086a1cd08a4621b3a21a2614e156c9",
            "c1d3979800224b51b92333fc2894aecd",
            "b02526e176544532a115eac987c601b4",
            "656ca7b0eeb34ec18fba2bbe37802fd8"
          ]
        },
        "id": "ebAyRr_jqRGC",
        "outputId": "2e394c19-fafb-4462-917b-07f937845db8"
      },
      "source": [
        "#model_checkpoint = 'bert-base-multilingual-uncased'\n",
        "model_checkpoint  = 'distilbert-base-uncased'\n",
        "transformer_model = transformers.AutoModel.from_pretrained(model_checkpoint)\n",
        "transformer_tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "transformer_config = transformers.AutoConfig.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5568e1c734ea4e13b4ff7bd5583ce4c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79c506d94a2140e585ffaf3b3e988d40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26c3ccf8cef74ca8a2b10dc0a1c938f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b880915de3b34d1c9bcd96d6fa673bf0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0a91baac5a844ef894fd3db3142a1d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6y068YhqTcQ"
      },
      "source": [
        "class NERDataSet(Dataset):\n",
        "    \"\"\"Generic NERDA DataSetReader\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                examples, \n",
        "                tokenizer: transformers.PreTrainedTokenizer,\n",
        "                tag_encoder: sklearn.preprocessing.LabelEncoder, \n",
        "                label_all_tokens: bool = False  \n",
        "                ) -> None:\n",
        "        \"\"\"Initialize DataSetReader\n",
        "        Initializes DataSetReader that prepares and preprocesses \n",
        "        DataSet for Named-Entity Recognition Task and training.\n",
        "        Args:\n",
        "            sentences (list): Sentences.\n",
        "            tags (list): Named-Entity tags.\n",
        "            transformer_tokenizer (transformers.PreTrainedTokenizer): \n",
        "                tokenizer for transformer.\n",
        "            transformer_config (transformers.PretrainedConfig): Config\n",
        "                for transformer model.\n",
        "            max_len (int): Maximum length of sentences after applying\n",
        "                transformer tokenizer.\n",
        "            tag_encoder (sklearn.preprocessing.LabelEncoder): Encoder\n",
        "                for Named-Entity tags.\n",
        "            tag_outside (str): Special Outside tag.\n",
        "        \"\"\"\n",
        "        self.sentences = examples['sentences']\n",
        "        self.tags = examples['tags']\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tag_encoder = tag_encoder\n",
        "        self.label_all_tokens = label_all_tokens\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        tags = self.tags[item]\n",
        "        # encode tags and sentence words\n",
        "        tags = self.tag_encoder.transform(tags)\n",
        "        tokenized_inputs = self.tokenizer(self.sentences[item], truncation=True, is_split_into_words=True)\n",
        "\n",
        "        word_ids = tokenized_inputs.word_ids()\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(tags[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.  A word could be split into two or more tokens occasionally depending on the model tokenizer\n",
        "            else:\n",
        "                label_ids.append(tags[word_idx] if self.label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        tokenized_inputs[\"target_tags\"] = label_ids\n",
        "        return tokenized_inputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWRY-zPYqXLV"
      },
      "source": [
        "def get_tag_scheme():\n",
        "    tag_scheme = [\n",
        "  'B-PER',\n",
        "  'I-PER',\n",
        "  'B-ORG',\n",
        "  'I-ORG',\n",
        "  'B-LOC',\n",
        "  'I-LOC',\n",
        "  'B-MISC',\n",
        "  'I-MISC'\n",
        "  ]\n",
        "    tag_outside = 'O'\n",
        "    tag_complete = [tag_outside] + tag_scheme\n",
        "    return tag_complete"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LpDz-kqqaBS"
      },
      "source": [
        "class NERDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size: int = 16, num_workers: int = 2):\n",
        "        super().__init__()\n",
        "   \n",
        "        # Defining batch size of our data\n",
        "        self.batch_size = batch_size\n",
        "          \n",
        "        # Defining num_workers\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        # Defining Tokenizers\n",
        "        self.tokenizer = transformer_tokenizer\n",
        "\n",
        "        self.label_pad_token_id = -100\n",
        "  \n",
        "    def prepare_data(self):\n",
        "        self.train_data = get_conll_data(split='train',dir='conll2003')\n",
        "        self.val_data = get_conll_data(split='valid',dir='conll2003')\n",
        "        self.test_data = get_conll_data(split='test',dir='conll2003')\n",
        "\n",
        "        self.tag_complete = get_tag_scheme()\n",
        "        self.tag_encoder = sklearn.preprocessing.LabelEncoder()\n",
        "        self.tag_encoder.fit(self.tag_complete)\n",
        "  \n",
        "    def setup(self, stage=None):\n",
        "        # Loading the dataset\n",
        "        self.train_dataset = NERDataSet(self.train_data, tokenizer=self.tokenizer, tag_encoder=self.tag_encoder, label_all_tokens=True)\n",
        "        self.val_dataset = NERDataSet(self.val_data, tokenizer=self.tokenizer, tag_encoder=self.tag_encoder, label_all_tokens=True)\n",
        "        self.test_dataset = NERDataSet(self.test_data, tokenizer=self.tokenizer, tag_encoder=self.tag_encoder, label_all_tokens=True)\n",
        "  \n",
        "    def custom_collate(self,features):\n",
        "        label_name = \"target_tags\"\n",
        "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
        "        \n",
        "        batch = self.tokenizer.pad(  \n",
        "            features,\n",
        "            padding=True,\n",
        "            # Conversion to tensors will fail if we have labels as they are not of the same length yet.\n",
        "            return_tensors=\"pt\" if labels is None else None,\n",
        "        )\n",
        "\n",
        "        if labels is None:\n",
        "            return batch\n",
        "\n",
        "        sequence_length = torch.tensor(batch[\"input_ids\"]).shape[1]\n",
        "        padding_side = self.tokenizer.padding_side\n",
        "        if padding_side == \"right\":\n",
        "            batch[label_name] = [label + [self.label_pad_token_id] * (sequence_length - len(label)) for label in labels]\n",
        "        else:\n",
        "            batch[label_name] = [[self.label_pad_token_id] * (sequence_length - len(label)) + label for label in labels]\n",
        "\n",
        "        batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
        "\n",
        "        return batch    \n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        #dist_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "        #return DataLoader(train_dataset, sampler=dist_sampler, batch_size=32) # For use in Multiple GPUs\n",
        "        return DataLoader(self.train_dataset, shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.custom_collate)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "         return DataLoader(self.val_dataset,batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.custom_collate)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.custom_collate)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.custom_collate)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqmml4JdqeLX"
      },
      "source": [
        "conll_dm = NERDataModule()\n",
        "conll_dm.prepare_data()\n",
        "conll_dm.setup()\n",
        "val_dataloader = conll_dm.val_dataloader()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_CH2UNqg9h"
      },
      "source": [
        "class NERModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                  n_tags: int, dropout: float = 0.1, \n",
        "                 **kwargs):\n",
        "    #def __init__(self, conf, **kwargs):   \n",
        "        super().__init__()\n",
        " \n",
        "        self.n_tags = n_tags\n",
        "        self.dropout = dropout\n",
        "        self.transformer = transformer_model\n",
        "        # extract transformer name\n",
        "        self.transformer_name = self.transformer.name_or_path\n",
        "        # extract AutoConfig, from which relevant parameters can be extracted.\n",
        "        self.transformer_config = transformer_config\n",
        "\n",
        "        \n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.tags = torch.nn.Linear(self.transformer_config.hidden_size, n_tags)\n",
        "    \n",
        "    def forward(self,  batch)-> torch.Tensor:\n",
        "        \"\"\"Model Forward Iteration\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input IDs.\n",
        "            masks (torch.Tensor): Attention Masks.\n",
        "            \n",
        "        Returns:\n",
        "            torch.Tensor: predicted values.\n",
        "        \"\"\"        \n",
        "\n",
        "        outputs = self.transformer(input_ids=batch['input_ids'], \\\n",
        "                         attention_mask=batch['attention_mask'])\n",
        "\n",
        "        hidden_state = outputs[0]  # (bs, seq_len, dim)\n",
        "        \n",
        "        # apply drop-out\n",
        "        outputs = self.dropout(hidden_state)\n",
        "\n",
        "        # outputs for all labels/tags\n",
        "        outputs = self.tags(outputs)\n",
        "\n",
        "        return outputs\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D94BbAUqkaK"
      },
      "source": [
        "class NERTokenClassifier(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, n_tags: int, learning_rate: float = 0.0001 * 8, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.n_tags = n_tags\n",
        "        # Metrics\n",
        "        self.metric = load_metric(\"seqeval\")       \n",
        "        self.model = NERModel(n_tags=self.n_tags)         \n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        target_tags = batch['target_tags']\n",
        "        # fwd\n",
        "        y_hat = self.model(batch)\n",
        "        \n",
        "        # loss\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        \n",
        "        # Compute active loss so as to not compute loss of paddings\n",
        "        active_loss = batch['attention_mask'].view(-1) == 1\n",
        "\n",
        "        active_logits = y_hat.view(-1, self.n_tags)\n",
        "        active_labels = torch.where(\n",
        "            active_loss,\n",
        "            target_tags.view(-1),\n",
        "            torch.tensor(loss_fct.ignore_index).type_as(target_tags)\n",
        "        )\n",
        "\n",
        "        # Only compute loss on actual token predictions\n",
        "        loss = loss_fct(active_logits, active_labels)\n",
        "\n",
        "        # logs\n",
        "        self.log_dict({'train_loss':loss}, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        target_tags = batch['target_tags']\n",
        "        # fwd\n",
        "        y_hat = self.model(batch)\n",
        "        \n",
        "        # loss\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        \n",
        "        # Compute active loss so as to not compute loss of paddings\n",
        "        active_loss = batch['attention_mask'].view(-1) == 1\n",
        "\n",
        "        active_logits = y_hat.view(-1, self.n_tags)\n",
        "        active_labels = torch.where(\n",
        "            active_loss,\n",
        "           target_tags.view(-1),\n",
        "            torch.tensor(loss_fct.ignore_index).type_as(target_tags)\n",
        "        )\n",
        "\n",
        "        # Only compute loss on actual token predictions\n",
        "        loss = loss_fct(active_logits, active_labels)\n",
        "\n",
        "        metrics = self.compute_metrics([y_hat,target_tags])\n",
        "\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log_dict({'val_loss':loss, 'val_f1':metrics['f1'], 'val_accuracy':metrics['accuracy'], \n",
        "                       'val_precision':metrics['precision'], 'val_recall':metrics['recall']}, prog_bar=True)\n",
        "        return loss    \n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "        target_tags = batch['target_tags']\n",
        "        # fwd\n",
        "        y_hat = self.model(batch)\n",
        "        \n",
        "        # loss\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        # Compute active loss so as to not compute loss of paddings\n",
        "        active_loss = batch['attention_mask'].view(-1) == 1\n",
        "\n",
        "        active_logits = y_hat.view(-1, self.n_tags)\n",
        "        active_labels = torch.where(\n",
        "            active_loss,\n",
        "            target_tags.view(-1),\n",
        "            torch.tensor(loss_fct.ignore_index).type_as(target_tags)\n",
        "        )\n",
        "\n",
        "        # Only compute loss on actual token predictions\n",
        "        loss = loss_fct(active_logits, active_labels)\n",
        "        metrics = self.compute_metrics([y_hat,target_tags])\n",
        "        \n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log_dict({'test_loss':loss, 'test_f1':metrics['f1'], 'test_accuracy':metrics['accuracy'], \n",
        "                       'test_precision':metrics['precision'], 'test_recall':metrics['recall']}, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        # fwd\n",
        "        y_hat = self.model(batch)\n",
        "        return {'logits':y_hat, \n",
        "                'target_tags':batch['target_tags'],\n",
        "                'input_ids':batch['input_ids'],\n",
        "                'attention_mask':batch['attention_mask']}\n",
        "\n",
        "    # ---------------------\n",
        "    # TRAINING SETUP\n",
        "    # ---------------------\n",
        "    def configure_optimizers(self):\n",
        "        # REQUIRED\n",
        "        # can return multiple optimizers and learning_rate schedulers\n",
        "        # (LBFGS it is automatically supported, no need for closure function)\n",
        "        optimizer = torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=self.hparams.learning_rate, eps=1e-08)\n",
        "        scheduler = {\n",
        "        'scheduler': torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-5, steps_per_epoch=len(self.trainer.datamodule.train_dataloader()), epochs=self.hparams.max_epochs),\n",
        "        'interval': 'step'  # called after each training step\n",
        "        } \n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-5, total_steps=2000)\n",
        "        #scheduler = StepLR(optimizer, step_size=1, gamma=0.2)\n",
        "        #scheduler = ReduceLROnPlateau(optimizer, patience=0, factor=0.2)\n",
        "\n",
        "        return [optimizer], [scheduler]\n",
        "        \n",
        "       \n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser, root_dir):  # pragma: no-cover\n",
        "        \"\"\"\n",
        "        Define parameters that only apply to this model\n",
        "        \"\"\"\n",
        "        parser = ArgumentParser(parents=[parent_parser])\n",
        "\n",
        "        # network params\n",
        "        #parser.add_argument('--drop_prob', default=0.2, type=float)\n",
        "\n",
        "        # data\n",
        "        parser.add_argument('--data_root', default=os.path.join(root_dir, 'train_val_data'), type=str)\n",
        "\n",
        "        # training params (opt)\n",
        "        parser.add_argument('--learning_rate', default=2e-5, type=float, help = \"type (default: %(default)f)\")\n",
        "        return parser\n",
        "    # ---------------------\n",
        "    # EVALUATE PERFORMANCE\n",
        "    # --------------------- \n",
        "\n",
        "    def compute_metrics(self,p):\n",
        "        predictions, labels = p\n",
        "        predictions = torch.argmax(predictions, dim=2)\n",
        "        label_len = len(self.trainer.datamodule.tag_complete)\n",
        "        label_list = self.trainer.datamodule.tag_encoder.inverse_transform(np.arange(label_len))\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        true_predictions = [\n",
        "          [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "          for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "          [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "          for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "\n",
        "        results = self.metric.compute(predictions=true_predictions, references=true_labels)\n",
        "        return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I-QbBepqnkU",
        "outputId": "328bf062-0440-4195-ab95-3084a6d942a0"
      },
      "source": [
        "# ------------------------\n",
        "# TRAINING ARGUMENTS\n",
        "# ------------------------\n",
        "# these are project-wide arguments\n",
        "root_dir = os.getcwd()\n",
        "parent_parser = ArgumentParser(add_help=False)\n",
        "parent_parser = pl.Trainer.add_argparse_args(parent_parser)\n",
        "\n",
        "# each LightningModule defines arguments relevant to it\n",
        "parser = NERTokenClassifier.add_model_specific_args(parent_parser,root_dir)\n",
        "\n",
        "parser.set_defaults(\n",
        "    #profiler='simple',\n",
        "    deterministic=True,\n",
        "    max_epochs=3,\n",
        "    gpus=1,\n",
        "    distributed_backend=None,\n",
        "    fast_dev_run=False,\n",
        "    model_load=False,\n",
        "    model_name='best_model',\n",
        "    n_tags = len(get_tag_scheme())\n",
        ")\n",
        "\n",
        "args, extra = parser.parse_known_args()\n",
        "\n",
        "\"\"\" Main training routine specific for this project. \"\"\"\n",
        "# ------------------------\n",
        "# 1 INIT LIGHTNING MODEL\n",
        "# ------------------------\n",
        "if (vars(args)['model_load']):\n",
        "    model = NERTokenClassifier.load_from_checkpoint(vars(args)['model_name'])\n",
        "else:  \n",
        "    model = NERTokenClassifier(**vars(args))\n",
        "print('n_tags',model.n_tags)\n",
        "# ------------------------\n",
        "# 2 CALLBACKS of MODEL\n",
        "# ------------------------\n",
        "\n",
        "# callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.0,\n",
        "    patience=3,\n",
        "    verbose=True,\n",
        "    mode='min',\n",
        "    strict=True,\n",
        ")\n",
        "\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "     monitor='val_loss',\n",
        "     #dirpath='my/path/',\n",
        "     filename='conll-ner-epoch{epoch:02d}-val_loss{val_loss:.2f}',\n",
        "     auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# 3 INIT TRAINER\n",
        "# ------------------------\n",
        "trainer = Trainer.from_argparse_args(args,\n",
        "    callbacks=[early_stop,lr_monitor,checkpoint_callback]\n",
        "    )    \n",
        "\n",
        "seed_everything(42, workers=True)\n",
        "conll_dm = NERDataModule()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_tags 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879,
          "referenced_widgets": [
            "66c461f186c341dd842fcf041d800758",
            "9a3ca8cf36874b4191a3c8a8bb72b8d4",
            "db70da18ce5140fba23e964d5b9d7cd2",
            "23d49ff962084ca79505bfa48f2fe7b4",
            "f16412a76e31424c84ce4150c47e8a38",
            "3cbaab0abe814caa9f5407b0637cf66e",
            "72ea52e2cea54049b7c34e77feddad09",
            "9760715e310c4fb9a4773e091c83096d",
            "fa5126718fe54aa0b67b5f9af49cefb6",
            "2231ae13c87c4bc5b577267464d968db",
            "25e4cf339aed4874a63282286583258e"
          ]
        },
        "id": "BdgjX3YHqrd0",
        "outputId": "52888585-e57f-42e7-dc34-c9a23ed8811b"
      },
      "source": [
        "# !pip install seqeval\n",
        "#  ------------------------\n",
        "# 4 START TRAINING\n",
        "# ------------------------\n",
        "trainer.fit(model,conll_dm)\n",
        "trainer.validate()\n",
        "trainer.test()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type     | Params\n",
            "-----------------------------------\n",
            "0 | model | NERModel | 66.4 M\n",
            "-----------------------------------\n",
            "66.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "66.4 M    Total params\n",
            "265.479   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66c461f186c341dd842fcf041d800758",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0881e781ed3f484997917c9550b2e29f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bab5b30fcda4b88b6b0184633703849",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Metric val_loss improved. New best score: 0.088\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b2ab7577a514851bc291cd38184c9f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "426a62869eea4305818c2640c211bc6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.061\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5a15f25f41f482fb097dcec0b73406c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 VALIDATE RESULTS\n",
            "{'val_accuracy': 0.9836896657943726,\n",
            " 'val_f1': 0.9224802255630493,\n",
            " 'val_loss': 0.06096518784761429,\n",
            " 'val_precision': 0.9163174033164978,\n",
            " 'val_recall': 0.9321487545967102}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5e400fe9cb4506b84798fffbf7ecaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_accuracy': 0.9711740016937256,\n",
            " 'test_f1': 0.8730692267417908,\n",
            " 'test_loss': 0.11419758200645447,\n",
            " 'test_precision': 0.8691366910934448,\n",
            " 'test_recall': 0.8799892663955688}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.9711740016937256,\n",
              "  'test_f1': 0.8730692267417908,\n",
              "  'test_loss': 0.11419758200645447,\n",
              "  'test_precision': 0.8691366910934448,\n",
              "  'test_recall': 0.8799892663955688}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "baa6bf6da8e84c54a3e4c9882574a414",
            "cdc1feab6eda476e8edbf160b8b72a18",
            "4f48db302a1b4c30aafccdcb9dd7d819",
            "c58bfa529e714697910dbccb2f77671a",
            "c47ef463635f4ebfb53af816a2366310",
            "66463dc7cbb2474da5faf8afe0da08fb",
            "84d5b4a6327a4a0188460f24267f3c1f",
            "f1c265a2214c41ef9cd780e98e7631c6",
            "835570069fa94ed0ae5087f077eaaa0d",
            "669d40ed0a014c13ae13704e28455301",
            "e7a2111cf276451c8adaf68374eb47a2"
          ]
        },
        "id": "VNPpHh0kq1E8",
        "outputId": "23eeba50-68a4-43c0-ad79-50813da491cd"
      },
      "source": [
        "## This will run the predict_step using the predict_dataloader.  The predict_step is made to return both the logits and labels for the Test data\n",
        "conll_dm = NERDataModule()\n",
        "conll_dm.prepare_data()\n",
        "conll_dm.setup()\n",
        "val_dataloader = conll_dm.val_dataloader()\n",
        "predict_with_labels = trainer.predict(dataloaders=val_dataloader)\n",
        "## flatten the Labels and Predictions after choosing the argmax of the each of the logits\n",
        "predictions_flat, labels_flat, input_ids_flat = [], [], []\n",
        "for index, batch in enumerate(predict_with_labels):\n",
        "    predictions, labels, input_ids = batch['logits'], batch['target_tags'], batch['input_ids']\n",
        "    predictions_flat.extend(torch.argmax(predictions, dim=2))\n",
        "    labels_flat.extend(labels)\n",
        "    input_ids_flat.extend(input_ids.cpu())\n",
        "\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "label_list = conll_dm.tag_encoder.inverse_transform(np.arange(9))\n",
        "\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions_flat, labels_flat)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions_flat, labels_flat)\n",
        "]\n",
        "true_input_ids = [\n",
        "    [i.item() for (i, l) in zip(id, label) if l != -100]\n",
        "    for id, label in zip(input_ids_flat, labels_flat)\n",
        "]\n",
        "\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "results"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baa6bf6da8e84c54a3e4c9882574a414",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Predicting: 878it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'f1': 0.953607271350123,\n",
              "  'number': 2618,\n",
              "  'precision': 0.9455501314307172,\n",
              "  'recall': 0.9618029029793735},\n",
              " 'MISC': {'f1': 0.8109633212414349,\n",
              "  'number': 1231,\n",
              "  'precision': 0.8048,\n",
              "  'recall': 0.8172217709179529},\n",
              " 'ORG': {'f1': 0.9000480538202787,\n",
              "  'number': 2056,\n",
              "  'precision': 0.889363722697056,\n",
              "  'recall': 0.9109922178988327},\n",
              " 'PER': {'f1': 0.974308300395257,\n",
              "  'number': 3034,\n",
              "  'precision': 0.9736668861092824,\n",
              "  'recall': 0.974950560316414},\n",
              " 'overall_accuracy': 0.9830356139759577,\n",
              " 'overall_f1': 0.9285396754834407,\n",
              " 'overall_precision': 0.9224908910235177,\n",
              " 'overall_recall': 0.9346683074169371}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ornz8GLZrDMK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}